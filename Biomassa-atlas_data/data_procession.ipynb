{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6b706ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import re\n",
    "from shapely.geometry import MultiPolygon, Polygon, Point\n",
    "from sklearn.cluster import KMeans\n",
    "from geopy.distance import distance\n",
    "from ast import literal_eval\n",
    "import math \n",
    "from geopy.distance import distance\n",
    "import pyproj\n",
    "import ast\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3ab970e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(df, title):\n",
    "    \n",
    "    # Separate x and y values from the coordinate tuples and get masses of each point\n",
    "    x_values = [row['Biomass location'][0] for _, row in df.iterrows()]\n",
    "    y_values = [row['Biomass location'][1] for _, row in df.iterrows()]\n",
    "    mass_values = df['Mass'].values\n",
    "\n",
    "    # To plot the coordinates in WGS84-system\n",
    "    \n",
    "    # Define the WGS84 and EUREF-FIN coordinate systems\n",
    "    wgs84 = pyproj.CRS('EPSG:4326')\n",
    "    euref_fin = pyproj.CRS('EPSG:3067')\n",
    "    \n",
    "    # Transform the location to WGS84 coordinates\n",
    "    transformer = pyproj.Transformer.from_crs(euref_fin, wgs84, always_xy=True)\n",
    "    x_values, y_values = transformer.transform(x_values,y_values)\n",
    "    \n",
    "    # Plot the data with the colors based on mass\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    sc = ax.scatter(x_values, y_values, c=mass_values, cmap='viridis', s=100)\n",
    "    plt.xlabel('Longitude', fontsize=14)\n",
    "    plt.ylabel('Latitude', fontsize=14)\n",
    "    plt.title(' '.join(title.split(' ')[:4]) + '\\n' + ' '.join(title.split(' ')[4:]), fontsize=16)\n",
    "    plt.tick_params(labelsize=12)\n",
    "    \n",
    "    # Add a colorbar to show the mass values\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.ax.set_ylabel('Mass (tonns)', fontsize=14)\n",
    "    \n",
    "    path = './pdfs/Biomasses/'\n",
    "    \n",
    "    if 'within the given radius' in title:\n",
    "        path = './pdfs/Biomasses within the given radius to the biogas facility/'\n",
    "    \n",
    "    fig.savefig(path + title+'.pdf')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "640fa5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(df,weighted_avg_centroids,sum_cluster_masses,pdfname, filename):\n",
    "    \n",
    "    masses_in_truck_capacity = np.array(sum_cluster_masses) / 45\n",
    "    \n",
    "    # Set up a colormap to color the centroids based on their sum of masses\n",
    "    cmap = plt.get_cmap('Reds')\n",
    "    norm = mcolors.LogNorm(vmin=np.array(masses_in_truck_capacity).min(), vmax=np.array(masses_in_truck_capacity).max())\n",
    "    #norm = plt.Normalize(np.array(masses_in_truck_capacity).min(), np.array(masses_in_truck_capacity).max())\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "    locations = df['Biomass location'].tolist()\n",
    "    locations = np.array(locations)\n",
    "    centroids = np.array(weighted_avg_centroids)\n",
    "    \n",
    "    # To plot the coordinates in WGS84-system,\n",
    "    # define the WGS84 and EUREF-FIN coordinate systems\n",
    "    wgs84 = pyproj.CRS('EPSG:4326')\n",
    "    euref_fin = pyproj.CRS('EPSG:3067')\n",
    "    \n",
    "    # Transform the location to WGS84 coordinates\n",
    "    transformer = pyproj.Transformer.from_crs(euref_fin, wgs84, always_xy=True)\n",
    "    x_values, y_values = transformer.transform(locations[:, 0],locations[:, 1])\n",
    "    x_centroids, y_centroids = transformer.transform(centroids[:, 0],centroids[:, 1])\n",
    "\n",
    "    # Plotting the data with the centroids\n",
    "\n",
    "    # scatter plot of data points and their clusters\n",
    "    plt.scatter(x_values, y_values, c=df['Cluster'])\n",
    "\n",
    "    # scatter plot of cluster centroids colored by their sum of masses\n",
    "    plt.scatter(x_centroids, y_centroids, marker='.', s=200, linewidths=3, c=masses_in_truck_capacity, cmap=cmap, norm=norm)\n",
    "\n",
    "    # Add a colorbar to show the logarithmic scale colormap legend\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.ax.set_ylabel('Masses in truckloads (45 tons)')\n",
    "    cbar.set_ticks([10, 100, 300])  # Customize the ticks on the colorbar\n",
    "    \n",
    "    plt.xlabel('Longitude', fontsize=14)\n",
    "    plt.ylabel('Latitude', fontsize=14)\n",
    "    plt.title('Pickup sites for the file '+' '.join(filename.split(' ')[:4]) + '\\n' + ' '.join(filename.split(' ')[4:]), fontsize=16)\n",
    "\n",
    "    path = './pdfs/Raw pickup sites/'\n",
    "\n",
    "    if 'Thinned' in pdfname:\n",
    "        path = './pdfs/Thinned out pickup sites/'\n",
    "    \n",
    "    fig.savefig(path + pdfname +filename+'.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d0b4e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_data(filename):\n",
    "    # Read the CSV file and specify the data types of the columns\n",
    "    dtypes = {'Area': str}\n",
    "    df = pd.read_csv(filename, header=0, sep=';', dtype=dtypes)\n",
    "\n",
    "    # Replace characters in the Area column and split it into separate columns\n",
    "    replacements = {'(': '', ')': '', 'MULTIPOLYGON': ''}\n",
    "    for index1, row in df.iterrows():\n",
    "        input_string = str(df['Area'][index1])\n",
    "        for old, new in replacements.items():\n",
    "            input_string = input_string.replace(old, new)\n",
    "        coordinates = input_string.split(',')\n",
    "        for index2, coordinate in enumerate(coordinates):\n",
    "            df.loc[index1,'Coordinate '+ str(index2)]=coordinate\n",
    "\n",
    "    # Calculate the mean points of biomass potentials and replace the coordinates with them\n",
    "    df2 = df[['Coordinate 0','Coordinate 1','Coordinate 2','Coordinate 3']]\n",
    "    df2 = df2.apply(lambda row: tuple(map(lambda x: np.sum(x)/len(x), zip(*[map(float, str(c).split()) for c in row]))), axis=1)\n",
    "    df['Biomass location'] = df2\n",
    "\n",
    "    # Clean the dataframe\n",
    "    df = df.loc[:, ['Mass','Biomass location']]\n",
    "    mask = df['Biomass location'].apply(is_2d_tuple)\n",
    "    df = df[mask]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0246c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df,radius,facilityloc):\n",
    "\n",
    "    # Clean the data (df) from the rows that are further away than the assumed maximum distance (radius)\n",
    "    # from the biogas facility locations (facilityloc). \n",
    "\n",
    "    # Check input parameters\n",
    "    if not isinstance(facilityloc, tuple) or len(facilityloc) != 2 or \\\n",
    "       not all(isinstance(x, (int, float)) for x in facilityloc):\n",
    "        raise ValueError('facilityloc must be a tuple with two numeric elements')\n",
    "\n",
    "    # Define the WGS84 and EUREF-FIN coordinate systems\n",
    "    wgs84 = pyproj.CRS('EPSG:4326')\n",
    "    euref_fin = pyproj.CRS('EPSG:3067')\n",
    "    \n",
    "    # Transform the facility location to EUREF-FIN coordinates\n",
    "    transformer = pyproj.Transformer.from_crs(wgs84, euref_fin, always_xy=True)\n",
    "    facility_euref_x, facility_euref_y = transformer.transform(facilityloc[1], facilityloc[0])\n",
    "    facility_loc = (facility_euref_x, facility_euref_y)\n",
    " \n",
    "    \n",
    "    # Calculate the distances\n",
    "    distances = df['Biomass location'].apply(lambda loc: math.sqrt(pow(facility_loc[0]-loc[0],2)+pow(facility_loc[1]-loc[1],2))/1000)\n",
    "\n",
    "    # Filter the data\n",
    "    df = df.loc[distances <= radius].reset_index(drop=True)\n",
    "    \n",
    "    # Remove zero masses from data\n",
    "    df = df.loc[(df != 0).all(axis=1)]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "937369f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_cluster_masses_and_locations(df):\n",
    "\n",
    "    # Getting masses and locations for each cluster\n",
    "\n",
    "    cluster_masses = [[] for _ in range(len(df['Cluster'].unique()))]\n",
    "    cluster_locations = [[] for _ in range(len(df['Cluster'].unique()))]\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        cluster_masses[row['Cluster']].append(row['Mass'])\n",
    "        cluster_locations[row['Cluster']].append(row['Biomass location'])\n",
    "\n",
    "    return cluster_masses, cluster_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cfb7072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_sums_and_weight_avg_centroids(df,cluster_masses,cluster_locations):\n",
    "    # Calculate the weighted average centroid for dataframe's clusters:\n",
    "\n",
    "    weighted_avg_centroids = []\n",
    "    sum_cluster_masses = []\n",
    "\n",
    "    for i in range(len(df['Cluster'].unique())):\n",
    "        sum_x = np.sum([mass * loc[0] for mass, loc in zip(cluster_masses[i], cluster_locations[i])])\n",
    "        sum_y = np.sum([mass * loc[1] for mass, loc in zip(cluster_masses[i], cluster_locations[i])])\n",
    "        weighted_avg_centroids.append((sum_x / np.sum(cluster_masses[i]), sum_y / np.sum(cluster_masses[i])))\n",
    "        sum_cluster_masses.append(np.sum(cluster_masses[i]))\n",
    "\n",
    "    return weighted_avg_centroids, sum_cluster_masses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f808f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_2d_tuple(val):\n",
    "    \n",
    "    # Check whether val given as parameter is in expected form of tuple. is used by load_and_process data.\n",
    "    \n",
    "    return isinstance(val, tuple) and len(val) == 2 and all(isinstance(x, (int, float)) for x in val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "70fd5599",
   "metadata": {},
   "outputs": [],
   "source": [
    "facility_loc = None \n",
    "greatest_distance = None\n",
    "\n",
    "def set_facility_loc_and_rad():\n",
    "    global facility_loc\n",
    "    global greatest_distance  \n",
    "    user_input = input(\"Give the coordinates of facility in inspection as a tuple: \")\n",
    "    trimmed_input = user_input.strip(\"())\")\n",
    "    coordinates = trimmed_input.split(\",\")\n",
    "    coordinates = [float(x) for x in coordinates]\n",
    "    facility_loc = tuple(coordinates)\n",
    "    greatest_distance = int(input(\"Give greatest distance of what biomasses are included: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a6867b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thin_clusters(df,tire_thickness,tires,cluster_divisor_coefficient,facility_loc):\n",
    "    \n",
    "    # Define the WGS84 and EUREF-FIN coordinate systems\n",
    "    wgs84 = pyproj.CRS('EPSG:4326')\n",
    "    euref_fin = pyproj.CRS('EPSG:3067')\n",
    "    \n",
    "    # Transform the facility location to EUREF-FIN coordinates\n",
    "    transformer = pyproj.Transformer.from_crs(wgs84, euref_fin, always_xy=True)\n",
    "    facility_euref_x, facility_euref_y = transformer.transform(facility_loc[1], facility_loc[0])\n",
    "    facility_loc = (facility_euref_x, facility_euref_y)\n",
    "    \n",
    "    # Calculate the distances\n",
    "    distances = df['Biomass location'].apply(lambda loc: math.sqrt(pow(facility_loc[0]-loc[0],2)+pow(facility_loc[1]-loc[1],2))/1000)\n",
    "    #i_values = {}  # Create an empty dictionary to store the separated dataframe names and their values\n",
    "    i_values = [None]*tires\n",
    "    \n",
    "    for i in range(tires,0,-1): # Reversed looping for handling the tires in a smarter way\n",
    "        \n",
    "        # Reordering the data to subsets of tires\n",
    "        i_values[tires-i] = df[(tire_thickness*(i-1) <= distances) & (distances <= tire_thickness*i)]  # Assign the filtered data to the corresponding tire\n",
    "\n",
    "        # Coordinates with mass coefficients of a data subset \n",
    "        coords = i_values[tires-i]['LocationWithMassCoefficient'].explode().tolist()\n",
    "\n",
    "        LocationMassCoords = [(coords[i], coords[i+1]) for i in range(0, len(coords)-1, 2)]\n",
    "        LocationMassCoords = np.array(LocationMassCoords)\n",
    "\n",
    "        # CLustering the data of a subset with k-value defined by cluster_divisor_coefficient. Thinning the cluster-areas from \n",
    "        # greater distance. Saving new clusters to ThinnedCLusters columns\n",
    "        previous_kluster_amount = len(i_values[tires-i]['Cluster'].unique()) # NOTE: IN ORIGINAL DATA, ONE CLUSTER MAY BE LOCATED TO MULTIPLE TIRE\n",
    "                                                                             # THIS SHOULD BE TAKEN IN NOTICE IN DECIDING cluster_divisor_coefficient     \n",
    "        kmeans = KMeans(n_clusters=int(previous_kluster_amount*pow(cluster_divisor_coefficient,i-1)),n_init='auto')\n",
    "        kmeans.fit(LocationMassCoords)\n",
    "\n",
    "        i_values[tires-i]['Cluster'] = kmeans.predict(i_values[tires-i]['Biomass location'].tolist())\n",
    "\n",
    "    return i_values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4cba4f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unite_dataframes_of_thinned_cluster_areas(dfs):\n",
    "\n",
    "    # Assuming your dataframes are stored in a list called \"dfs\"\n",
    "    \n",
    "    for i, df in enumerate(dfs):\n",
    "        if i == 0:\n",
    "            combined_df = df\n",
    "            continue\n",
    "        \n",
    "        clustersAdded = int(len(combined_df['Cluster'].unique()))\n",
    "        \n",
    "        df['Cluster'] = df['Cluster']+clustersAdded\n",
    "        \n",
    "        combined_df = pd.concat([combined_df,df])\n",
    "        \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f86cd0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_biomasses_with_KMeans(df,k):\n",
    "    \n",
    "    # To duplicate the coordinate points based on their masses to consider\n",
    "    # the geographical distribution of masses in clustering.\n",
    "    \n",
    "    df['MassCoefficient'] = df['Mass'].apply(round).astype(int).clip(lower=1)\n",
    "    df['LocationWithMassCoefficient'] = df['Biomass location'] * df['MassCoefficient']\n",
    "    coords = df['LocationWithMassCoefficient'].explode().tolist()\n",
    "    LocationMassCoords = [(coords[i], coords[i+1]) for i in range(0, len(coords)-1, 2)]\n",
    "    LocationMassCoords = np.array(LocationMassCoords)    \n",
    "\n",
    "    # fitting the mass-distribution fixed data with KMeans\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=k,n_init='auto')\n",
    "    kmeans.fit(LocationMassCoords)\n",
    "    \n",
    "    locations = df['Biomass location'].tolist()\n",
    "    locations = np.array(locations)\n",
    "\n",
    "    # Making predictions of cluster for each coordinate point \n",
    "    df['Cluster'] = kmeans.predict(locations)\n",
    "    \n",
    "    return df, kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "576968f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euref_fin_to_lon_lat(row):\n",
    "    \n",
    "    # Simple function to convert EUREF-FIN coordinates to lon-lat\n",
    "    \n",
    "    etrs_tm35fin = pyproj.Proj(\"+proj=utm +zone=35 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\")\n",
    "    lon, lat = etrs_tm35fin(row['ClusterLocations'][0], row['ClusterLocations'][1], inverse=True)\n",
    "    return pd.Series({'lon': lon, 'lat': lat})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e6fb9b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toGeoJSONs(centroids,masses,file):\n",
    "\n",
    "    # Transfers and saves clusters into a geojson format. \n",
    "    df = pd.DataFrame({'ClusterLocations': centroids, 'Clustermasses': masses}, index=range(1, len(centroids)+1))\n",
    "    \n",
    "    df[['lon','lat']] = df.apply(euref_fin_to_lon_lat,axis=1)\n",
    "\n",
    "    geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometry, crs='EPSG:4326')\n",
    "    gdf = gdf.drop('ClusterLocations',axis=1) \n",
    "\n",
    "    ## save the GeoDataFrame to a GeoJSON file\n",
    "    path = './geojsons/'\n",
    "    gdf.to_file(path + file+'.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6b3c1cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf['MassCoefficient'] = df['Mass'].apply(round).astype(int).clip(lower=1)\\ndf['LocationWithMassCoefficient'] = df['Biomass location'] * df['MassCoefficient']\\n\\ncoords = df['LocationWithMassCoefficient'].explode().tolist()\\nLocationMassCoords = [(coords[i], coords[i+1]) for i in range(0, len(coords)-1, 2)]\\nLocationMassCoords = np.array(LocationMassCoords)\\n\\nk_vals = list(range(1,100))\\nwcss = []\\nlabels=[]\\n\\nfor i in k_vals:    \\n    kmeans = KMeans(n_clusters=i,n_init='auto')\\n    kmeans.fit(LocationMassCoords)\\n    wcss.append(kmeans.inertia_)\\n    labels.append(kmeans.predict(LocationMassCoords))\\n\""
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tsekkaa paperi GIS-data related route optimization, hierarchical clustering, location\n",
    "# optimization, and kernel density methods are useful for promoting\n",
    "# distributed bioenergy plant planning in rural areas\n",
    "# K. Laasasenahoa*, A. Lensub*, R. Lauhanenc\n",
    "# and J. Rintalaa\n",
    "\n",
    "# Clustering the data with K-means. Utilzing the elbow method to decide optimal value for k.\n",
    "# The basic idea in elbow method is to plot the within-cluster \n",
    "# sum of squares (WCSS) against the number of clusters, and choose the number of clusters \n",
    "# at the \"elbow\" point where the rate of decrease in WCSS slows down significantly.\n",
    "\n",
    "# To be used in consideration of mass distribution. Each coordinate will be multiplied \n",
    "# with their MassCoefficient in clustering\n",
    "# to give more weight to the points with greater mass. \n",
    "'''\n",
    "df['MassCoefficient'] = df['Mass'].apply(round).astype(int).clip(lower=1)\n",
    "df['LocationWithMassCoefficient'] = df['Biomass location'] * df['MassCoefficient']\n",
    "\n",
    "coords = df['LocationWithMassCoefficient'].explode().tolist()\n",
    "LocationMassCoords = [(coords[i], coords[i+1]) for i in range(0, len(coords)-1, 2)]\n",
    "LocationMassCoords = np.array(LocationMassCoords)\n",
    "\n",
    "k_vals = list(range(1,100))\n",
    "wcss = []\n",
    "labels=[]\n",
    "\n",
    "for i in k_vals:    \n",
    "    kmeans = KMeans(n_clusters=i,n_init='auto')\n",
    "    kmeans.fit(LocationMassCoords)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    labels.append(kmeans.predict(LocationMassCoords))\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f81393cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.plot(range(1, 100), wcss)\\nplt.title('Elbow Method')\\nplt.xlabel('Number of clusters')\\nplt.ylabel('WCSS')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the WCSS values against the number of clusters\n",
    "'''\n",
    "plt.plot(range(1, 100), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8b1ea8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the graph above, close to optimal and good enough k-values for this datasets is 60.\n",
    "# Let's plot the data with 60 clusters.\n",
    "# Plotting the data\n",
    "\n",
    "# Because of the later trimming data from the clusters far away from the facility, initialize clustering with K=200\n",
    "\n",
    "#KCLUSTERS = 200\n",
    "\n",
    "#kmeans = KMeans(n_clusters=KCLUSTERS,n_init='auto')\n",
    "#kmeans.fit(LocationMassCoords)\n",
    "#labels = kmeans.predict(LocationMassCoords)\n",
    "#plt.scatter(LocationMassCoords[:,0],LocationMassCoords[:,1],c=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ba8b1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    filename = input(\"Enter biomassdata filename: \") + '.csv'\n",
    "    folder = input(\"Enter the name of the folder where the file is located: \")\n",
    "    path = './datasets/'\n",
    "    set_facility_loc_and_rad()\n",
    "    df = load_and_process_data(path+'/'+folder+'/'+filename)\n",
    "    file = filename.split('.',1)[0]\n",
    "    # Coordinates for Envor's facility: (60.929833, 23.369694)\n",
    "\n",
    "    plot_data(df,'Biomasses of ' + file)\n",
    "\n",
    "    df = clean_data(df,greatest_distance,facility_loc)\n",
    "\n",
    "    plot_data(df,file+' within the given radius to the biogas facility')\n",
    "\n",
    "    df, kmeans = cluster_biomasses_with_KMeans(df,200)\n",
    "\n",
    "    cluster_masses, cluster_locations =  df_cluster_masses_and_locations(df)\n",
    "\n",
    "    weighted_avg_centroids, sum_cluster_masses = cluster_sums_and_weight_avg_centroids(df,cluster_masses, cluster_locations)\n",
    "\n",
    "    plot_clusters(df,weighted_avg_centroids,sum_cluster_masses,'Raw pickup sites for the file ',file)\n",
    "\n",
    "    thinned_and_clustered_tires = thin_clusters(df,10,5,0.7,facility_loc)\n",
    "\n",
    "    thinned_area = unite_dataframes_of_thinned_cluster_areas(thinned_and_clustered_tires)\n",
    "\n",
    "    thinned_cluster_masses, thinned_cluster_locations =  df_cluster_masses_and_locations(thinned_area)\n",
    "\n",
    "    thinned_weighted_avg_centroids, thinned_sum_cluster_masses = cluster_sums_and_weight_avg_centroids(thinned_area,thinned_cluster_masses, thinned_cluster_locations)\n",
    "\n",
    "    plot_clusters(thinned_area,thinned_weighted_avg_centroids, thinned_sum_cluster_masses,'Thinned out pickup sites for the file ' , file)\n",
    "\n",
    "    toGeoJSONs(thinned_weighted_avg_centroids,thinned_sum_cluster_masses,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6b9c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter biomassdata filename: SivuvirtaOlki2021\n",
      "Enter the name of the folder where the file is located: Nurmet ja oljet\n",
      "Give the coordinates of facility in inspection as a tuple: (60.929833, 23.369694)\n",
      "Give greatest distance of what biomasses are included: 50\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b217c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
